name: dkube_metricsviz
description: Visualizer for dkube metrics
metadata:
  annotations: {platform: Dkube}
  labels:
    platform: Dkube
    logger: dkubepl
    dkube.garbagecollect: "false"
    dkube.garbagecollect.policy: all
    wfid: '{{workflow.uid}}'
    runid: '{{pod.name}}'
inputs:
- {name: user, type: String}
- {name: token, type: String}
- {name: run_details, type: String}
outputs:
- {name: mlpipeline_metrics, type: Metrics}
implementation:
  container:
    image: ocdr/dkube_launcher:viz
    command:
    - python3
    - -u
    - -c
    - |
      def visualize(user, token, run_details):
          import json
          import pandas as pd
          from minio import Minio
          from dkube.sdk.api import DkubeApi

          print(run_details)
          details = json.loads(run_details)
          jobname = details['Jobname']
          api = DkubeApi(token=token)
          lineage = api.get_training_run_lineage(user, jobname)

          print(lineage)
          model = lineage['run']['parameters']['training']['datums']['outputs'][0]['name']
          version = lineage['run']['parameters']['training']['datums']['outputs'][0]['version']

          model = model.split(':')[1]
          metrics_url = "/users/{}/model/{}/{}/data/metrics/metrics.csv".format(user, model, version)
          print(metrics_url)

          client = Minio(
              "dkube-minio-server.dkube-infra:9000",
              access_key="dkube",
              secret_key="l06dands19s",
              secure=False
          )

          obj = client.get_object(
              "dkube",
              metrics_url,
          )

          metrics = []
          df = pd.read_csv(obj)
          for (name, value) in df.iteritems():
              print(name)
              print(value.values[0])
              metric = {"name": name.strip(), "numberValue": value.values[0]}
              metrics.append(metric)

          metrics = {'metrics': metrics}
          print(metrics)

          return [json.dumps(metrics)]

      import argparse
      _parser = argparse.ArgumentParser(prog='dkube_metricsviz', description='Visualizer for dkube metrics')
      _parser.add_argument("--user", dest="user", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--token", dest="token", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--run-details", dest="run_details", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
      _parsed_args = vars(_parser.parse_args())
      _output_files = _parsed_args.pop("_output_paths", [])

      _outputs = visualize(**_parsed_args)

      _output_serializers = [
          str,

      ]

      import os
      for idx, output_file in enumerate(_output_files):
          try:
              os.makedirs(os.path.dirname(output_file))
          except OSError:
              pass
          with open(output_file, 'w') as f:
              f.write(_output_serializers[idx](_outputs[idx]))
    args:
    - --user
    - {inputValue: user}
    - --token
    - {inputValue: token}
    - --run-details
    - {inputValue: run_details}
    - '----output-paths'
    - {outputPath: mlpipeline_metrics}
    env:
      pipeline: "true"
      wfid: '{{workflow.uid}}'
      runid: '{{pod.name}}'

